{
 "metadata": {
  "name": "turk-analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports\n",
      "import collections\n",
      "import matplotlib.cm as cm\n",
      "import matplotlib.gridspec as gridspec\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pdb\n",
      "import pickle\n",
      "import scipy.stats\n",
      "import os\n",
      "import time\n",
      "\n",
      "import cogphysics\n",
      "import cogphysics.lib.circ as circ\n",
      "import cogphysics.lib.nplib as npl\n",
      "import cogphysics.lib.rvs as rvs\n",
      "\n",
      "import cogphysics.tower.analysis_tools as tat\n",
      "import cogphysics.tower.mass.model_observer as mo\n",
      "import cogphysics.tower.mass.learning_analysis_tools as lat\n",
      "\n",
      "from cogphysics.lib.corr import xcorr, partialcorr\n",
      "\n",
      "normalize = rvs.util.normalize\n",
      "weightedSample = rvs.util.weightedSample\n",
      "\n",
      "pd.set_option('line_width', 195)\n",
      "LINE = \"-\"*195\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Load stimuli\n",
      "######################################################################\n",
      "\n",
      "listpath = os.path.join(cogphysics.CPOBJ_LIST_PATH,\n",
      "\t\t\t\"mass-towers-stability-learning~kappa-1.0\")\n",
      "with open(listpath, \"r\") as fh:\n",
      "    Stims = np.array([x.split(\"~\")[0] for x in fh.read().strip().split(\"\\n\") if x != \"\"])\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training = {}\n",
      "posttest = {}\n",
      "experiment = {}\n",
      "queries = {}\n",
      "    "
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Check human data for bad participants\n",
      "######################################################################\n",
      "\n",
      "dfs = []\n",
      "suffix = ['-cb0', '-cb1']\n",
      "for c in ['B-fb-10', 'B-fb-0.1', 'B-nfb-10']:\n",
      "    for s in suffix:\n",
      "\tcond = c + s\n",
      "\tdfs.append(lat.load_turk_df(cond, \"posttest\"))\n",
      "\n",
      "for cond in posttest.keys():\n",
      "    dfs.append(posttest[cond])\n",
      "df = pd.concat(dfs)\n",
      "mean = df.mean(axis=0)\n",
      "print\n",
      "print mean\n",
      "wrong = (df != mean.round()).sum(axis=1)\n",
      "bad = wrong > 1\n",
      "pids = sorted(list((bad).index[(bad).nonzero()]))\n",
      "print\n",
      "print \"Bad pids: \", pids\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb1.npz'\n",
        "\n",
        "trial  stimulus      \n",
        "4      stability01023    0.063492\n",
        "1      stability01178    0.126984\n",
        "3      stability01491    0.952381\n",
        "0      stability01654    0.888889\n",
        "2      stability01893    0.158730\n",
        "5      stability01967    0.936508\n",
        "\n",
        "Bad pids:  ['002', '012', '015', '020', '021', '023', '024', '059']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Load human data\n",
      "######################################################################\n",
      "\n",
      "reload(lat)\n",
      "suffix = ['-cb0', '-cb1']\n",
      "for cond in ['B-fb-10', 'B-fb-0.1', 'B-nfb-10']:\n",
      "    conds = [cond+s for s in suffix]\n",
      "    for c in conds:\n",
      "\ttraining[c] = lat.load_turk_df(c, \"training\", exclude=pids)\n",
      "\tposttest[c] = lat.load_turk_df(c, \"posttest\", exclude=pids)\n",
      "\texperiment[c] = lat.load_turk_df(c, \"experiment\", exclude=pids)\n",
      "\tif cond.split(\"-\")[1] != \"nfb\":\n",
      "\t    queries[c] = lat.load_turk_df(c, \"queries\", exclude=pids)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-0.1-cb0.npz'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-nfb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-nfb-10-cb1.npz'\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Load model data\n",
      "######################################################################\n",
      "\n",
      "nthresh0 = 0\n",
      "nthresh = 0.4\n",
      "\n",
      "reload(lat)\n",
      "rawtruth0, rawipe0, rawsstim, kappas = lat.load_model(\"stability\")\n",
      "truth0 = lat.make_truth_df(rawtruth0, rawsstim, kappas, nthresh0)\n",
      "ipe0 = lat.make_ipe_df(rawipe0, rawsstim, kappas, nthresh)\n",
      "\n",
      "hstim = np.array([x.split(\"~\")[0] for x in zip(*experiment['B-fb-10-cb0'].columns)[1]])\n",
      "sstim = np.array(ipe0.columns)\n",
      "idx = np.nonzero((sstim[:, None] == hstim[None, :]))[1]\n",
      "\n",
      "truth = truth0.T.ix[idx].T\n",
      "ipe = ipe0.T.ix[idx].T\n",
      "feedback = np.asarray(truth).T[..., None]\n",
      "nfell = (rawipe0[idx]['nfellA'] + rawipe0[idx]['nfellB']) / 10.0\n",
      "ipe_samps = (nfell > nthresh)[..., None].astype('f8')\n",
      "ipe_samps[np.isnan(nfell)] = 0.5\n",
      "\n",
      "fig = plt.figure(1)\n",
      "plt.clf()\n",
      "lat.plot_smoothing(rawipe0[idx], hstim, 6, nthresh, kappas)\n",
      "fig.set_figheight(6)\n",
      "fig.set_figwidth(8)\n",
      "\n",
      "lat.save(\"images/likelihood_smoothing.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving figure to images/likelihood_smoothing.png...' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Global parameters\n",
      "######################################################################\n",
      "\n",
      "n_kappas = len(kappas)\n",
      "ratios = 10 ** kappas\n",
      "ratios[kappas < 0] = np.round(ratios[kappas < 0], decimals=2)\n",
      "ratios[kappas >= 0] = np.round(ratios[kappas >= 0], decimals=1)\n",
      "\n",
      "outcomes     = np.array([0, 1])                  # possible outcomes\n",
      "n_trial      = hstim.size\n",
      "n_outcomes   = outcomes.size                     # number of possible outcomes\n",
      "\n",
      "f_smooth = True\n",
      "p_ignore_stimulus = 0.0\n",
      "\n",
      "cmap = lat.make_cmap(\"lh\", (0, 0, 0), (.5, .5, .5), (1, 0, 0))\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Generate fake human data\n",
      "######################################################################\n",
      "nfake = 50\n",
      "for cond in experiment.keys():\n",
      "\n",
      "    if cond.startswith(\"MO-\"):\n",
      "\tcontinue\n",
      "\n",
      "    cols = experiment[cond].columns\n",
      "    order = np.argsort(zip(*cols)[0])\n",
      "    undo_order = np.argsort(order)\n",
      "    \n",
      "    # learning model beliefs\n",
      "    model_lh, model_joint, model_theta = mo.ModelObserver(\n",
      "\tipe_samps[order],\n",
      "\tfeedback[order][:, None],\n",
      "\toutcomes=None,\n",
      "\trespond=False,\n",
      "\tp_ignore_stimulus=p_ignore_stimulus,\n",
      "\tsmooth=f_smooth)\n",
      "    \n",
      "    p_outcomes = np.empty((n_trial,))\n",
      "    args = cond.split(\"-\")\n",
      "    if len(args) > 2:\n",
      "\ttidx = list(ratios).index(float(args[2]))\n",
      "    else:\n",
      "\ttidx = None\n",
      "\t\n",
      "    for t in xrange(n_trial):\n",
      "\tif args[1] == \"nfb\":\n",
      "\t    thetas = [\n",
      "\t\tnp.log(np.zeros(n_kappas)),\n",
      "\t\tnormalize(np.log(np.ones(n_kappas)))[1]]\n",
      "\t    thetas[0][list(kappas).index(0.0)] = 0\n",
      "\t    newconds = [\n",
      "\t\t\"-\".join([\"MO-nfb-1.0\"] + args[3:]),\n",
      "\t\t\"-\".join([\"MO-nfb\"] + args[3:])]\n",
      "\t\t\n",
      "\telif args[1] == \"fb\":\n",
      "\t    thetas = [\n",
      "\t\tnp.log(np.zeros(n_kappas)),\n",
      "\t\tmodel_theta[tidx, t]\n",
      "\t\t]\n",
      "\t    thetas[0][tidx] = 0\n",
      "\t    newconds = [\"-\".join([\"MO-nfb\"] + args[2:]),\n",
      "\t\t\t\"-\".join([\"MO-fb\"] + args[2:])]\n",
      "\n",
      "\tfor theta, newcond in zip(thetas, newconds):\n",
      "\t    p_outcomes[t] = np.exp(mo.predict(\n",
      "\t\t    theta[None],\n",
      "\t\t    outcomes[:, None], \n",
      "\t\t    ipe_samps[order][t],\n",
      "\t\t    f_smooth)).ravel()[1]\n",
      "\t    responses = np.random.rand(nfake)[:, None] < p_outcomes[None]\t\t\n",
      "\t    experiment[newcond] = pd.DataFrame(\n",
      "\t\t    responses[:, undo_order], \n",
      "\t\t    columns=cols)\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(lat)\n",
      "fig = plt.figure(2)\n",
      "plt.clf()\n",
      "lat.plot_belief(model_theta, kappas, cmap)\n",
      "fig.set_figwidth(8)\n",
      "fig.set_figheight(2.5)\n",
      "\n",
      "lat.save(\"images/ideal_learning_observers.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving figure to images/ideal_learning_observers.png...' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cond_labels = {\n",
      "    # 'A-nfb': 'No feedback',\n",
      "    # 'A-fb': 'Feedback',\n",
      "    # 'A-fb-ideal0.1-mo': 'Learning observer, r=0.1',\n",
      "    # 'A-fb-ideal10-mo': 'Learning observer, r=10',\n",
      "    # 'A-fb-fixed0.1-mo': 'Fixed Observer, r=0.1',\n",
      "    # 'A-fb-fixed10-mo': 'Fixed Observer, r=10'\n",
      "    'B-nfb-10': 'Human no-feedback',\n",
      "    'B-fb-0.1': '(r=0.1) Human feedback',\n",
      "    'B-fb-10': '(r=10) Human feedback',\n",
      "    'MO-nfb': 'Uniform fixed observer',\n",
      "    'MO-nfb-1.0': '(r=1) Fixed observer',\n",
      "    'MO-fb-0.1': '(r=0.1) Learning observer',\n",
      "    'MO-fb-10': '(r=10) Learning observer',\n",
      "    'MO-nfb-0.1': '(r=0.1) Fixed observer',\n",
      "    'MO-nfb-10': '(r=10) Fixed observer',\n",
      "    }\n",
      "\n",
      "conds = sorted(experiment.keys())\n",
      "condsort = np.argsort(cond_labels.values())\n",
      "newconds = list([str(x) for x in np.array(cond_labels.keys())[condsort]])\n",
      "n_cond = len(newconds)\n",
      "\n",
      "# cond_labels = dict([(c, c) for c in conds])\n",
      "# newconds = sorted(np.unique([\"-\".join(c.split(\"-\")[:-1]) for c in conds]))\n",
      "    "
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# bootstrapped correlations\n",
      "reload(lat)\n",
      "\n",
      "nboot = 1000\n",
      "nsamp = 9\n",
      "with_replacement = False\n",
      "\n",
      "for cond in newconds:\n",
      "\n",
      "    arr1 = np.asarray(experiment[cond + '-cb0'])\n",
      "    arr2 = np.asarray(experiment[cond + '-cb1'])\n",
      "    arr3 = np.vstack([arr1, arr2])\n",
      "\n",
      "    corrs = lat.bootcorr(\n",
      "\tnp.asarray(arr1), np.asarray(arr2), \n",
      "\tnboot=nboot, \n",
      "\tnsamp=nsamp,\n",
      "\twith_replacement=with_replacement)\n",
      "    meancorr = np.median(corrs)\n",
      "    semcorr = scipy.stats.sem(corrs)\n",
      "    print \"(bootstrap) %-15s v %-15s: rho = %.4f +/- %.4f\" % (\n",
      "\tcond+\"-cb0\", cond+\"-cb1\", meancorr, semcorr)\n",
      "\n",
      "    corrs = lat.bootcorr_wc(\n",
      "\tnp.asarray(arr3), \n",
      "\tnboot=nboot,\n",
      "\tnsamp=nsamp,\n",
      "\twith_replacement=with_replacement)\n",
      "    meancorr = np.median(corrs)\n",
      "    semcorr = scipy.stats.sem(corrs)\n",
      "    print \"(bootstrap) %-15s v %-15s: rho = %.4f +/- %.4f\" % (\n",
      "\tcond, cond, meancorr, semcorr)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(bootstrap) MO-nfb-0.1-cb0  v MO-nfb-0.1-cb1 : rho = 0.8834 +/- 0.0019\n",
        "(bootstrap) MO-nfb-0.1      v MO-nfb-0.1     : rho = 0.9033 +/- 0.0022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-0.1-cb0    v B-fb-0.1-cb1   : rho = 0.1059 +/- 0.0010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-0.1        v B-fb-0.1       : rho = 0.3656 +/- 0.0044"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-0.1-cb0   v MO-fb-0.1-cb1  : rho = 0.8705 +/- 0.0023"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-0.1       v MO-fb-0.1      : rho = 0.8952 +/- 0.0022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-nfb-1.0-cb0  v MO-nfb-1.0-cb1 : rho = 0.8710 +/- 0.0034"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-nfb-1.0      v MO-nfb-1.0     : rho = 0.9003 +/- 0.0026"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-nfb-10-cb0   v MO-nfb-10-cb1  : rho = 0.9213 +/- 0.0019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-nfb-10       v MO-nfb-10      : rho = 0.9144 +/- 0.0021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-10-cb0     v B-fb-10-cb1    : rho = 0.2698 +/- 0.0024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-10         v B-fb-10        : rho = 0.5950 +/- 0.0038"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-10-cb0    v MO-fb-10-cb1   : rho = 0.8919 +/- 0.0021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-10        v MO-fb-10       : rho = 0.9026 +/- 0.0022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-nfb-10-cb0    v B-nfb-10-cb1   : rho = 0.7163 +/- 0.0011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-nfb-10        v B-nfb-10       : rho = 0.7296 +/- 0.0028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-nfb-cb0      v MO-nfb-cb1     : rho = 0.9059 +/- 0.0025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-nfb          v MO-nfb         : rho = 0.8990 +/- 0.0027"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collapse(data):\n",
      "    stacked = [np.vstack([data[c] for c in conds if c.startswith(nc)]) for nc in newconds]\n",
      "    means = np.array([np.mean(x, axis=0) for x in stacked])\n",
      "    sems = np.array([scipy.stats.sem(x, axis=0) for x in stacked])\n",
      "    sems[np.isnan(sems)] = 0\n",
      "    mean = np.log(means)\n",
      "    lower = np.log(means - sems)\n",
      "    upper = np.log(means + sems)\n",
      "    out = np.array([mean, lower, upper]).T\n",
      "    return out\n",
      "\t"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ir1 = list(kappas).index(0.0)\n",
      "ir10 = list(kappas).index(1.0)\n",
      "ir01 = list(kappas).index(-1.0)\n",
      "reload(lat)\n",
      "\n",
      "# random model\n",
      "model_random = collapse(lat.random_model_lh(conds, n_trial))[0]\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(lat)\n",
      "\n",
      "# fixed models\n",
      "thetas = np.zeros((3, n_trial+1, n_kappas))\n",
      "thetas[0, :, ir1] = 1\n",
      "thetas[1, :, ir10] = 1\n",
      "thetas[2, :, ir01] = 1\n",
      "model_same, model_true10, model_true01 = collapse(lat.fixed_model_lh(\n",
      "    conds, experiment, ipe_samps, np.log(thetas), f_smooth=f_smooth))\n",
      "\t"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(lat)\n",
      "\n",
      "# learning models\n",
      "model_learn01, model_learn10 = collapse(lat.learning_model_lh(\n",
      "    conds, experiment, ipe_samps, feedback, [ir01, ir10], f_smooth=f_smooth))\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# all the models\n",
      "models = np.array([\n",
      "    model_random,\n",
      "    model_true01,\n",
      "    model_learn01,\n",
      "    # model_same,\n",
      "    model_true10,\n",
      "    model_learn10\n",
      "    ]).T\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta = np.log(np.eye(n_kappas)[:, None] * np.ones((n_kappas, n_trial+1, n_kappas)))\n",
      "mean, upper, lower = collapse(lat.fixed_model_lh(\n",
      "    conds, experiment, ipe_samps, theta, f_smooth=f_smooth)).T\n",
      "\n",
      "x = np.arange(n_kappas)\n",
      "fig = plt.figure(3)\n",
      "plt.clf()\n",
      "\n",
      "colors = ['r', '#FF9966', '#AAAA00', 'g', 'c', 'b', '#9900FF', 'm']\n",
      "for cidx, cond in enumerate(newconds):\n",
      "    color = colors[cidx % len(colors)]\n",
      "    if cidx >= len(colors):\n",
      "\tlinestyle = '--'\n",
      "    else:\n",
      "\tlinestyle = '-'\n",
      "    plt.fill_between(x, lower[cidx], upper[cidx], color=color, alpha=0.1)\n",
      "    plt.plot(x, mean[cidx], label=cond_labels[cond], color=color, linewidth=2,\n",
      "\t     linestyle=linestyle)\n",
      "\n",
      "plt.xticks(x, ratios, rotation=90)\n",
      "plt.xlabel(\"Fixed model mass ratio\")\n",
      "plt.ylabel(\"Log likelihood of responses\")\n",
      "plt.legend(loc=4, ncol=2)\n",
      "plt.xlim(x[0], x[-1])\n",
      "plt.ylim(-24, -8)\n",
      "plt.title(\"Likelihood of responses under fixed models\")\n",
      "fig.set_figwidth(8)\n",
      "fig.set_figheight(6)\n",
      "\n",
      "lat.save(\"images/fixed_model_performance.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving figure to images/fixed_model_performance.png...' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot model performance\n",
      "x0 = np.arange(models.shape[2])\n",
      "height = models[0]\n",
      "err = np.abs(models[[0]] - models[1:])\n",
      "width = 0.7 / n_cond\n",
      "fig = plt.figure(4)\n",
      "plt.clf()\n",
      "\n",
      "for cidx, cond in enumerate(newconds):\n",
      "    color = colors[cidx % len(colors)]\n",
      "    x = x0 + width*(cidx-(n_cond/2.)) + (width/2.)\n",
      "    plt.bar(x, height[cidx], yerr=err[:, cidx], color=color,\n",
      "\t    ecolor='k', align='center', width=width, label=cond_labels[cond])\n",
      "\n",
      "plt.xticks(x0, [\n",
      "    \"Random\", \n",
      "    \"Fixed\\nr=0.1\",\n",
      "    \"Learning\\nr=0.1\",\n",
      "    # \"Fixed\\nr=1.0\", \n",
      "    \"Fixed\\nr=10.0\", \n",
      "    \"Learning\\nr=10.0\"\n",
      "    ])\n",
      "#plt.ylim(int(np.min(height-err))-1, int(np.max(height))+1)\n",
      "plt.ylim(-25, -5)\n",
      "plt.xlim(x0.min()-0.5, x0.max()+0.5)\n",
      "plt.legend(loc=0, ncol=2)\n",
      "plt.xlabel(\"Model\", fontsize=14)\n",
      "plt.ylabel(\"Log likelihood of responses, $\\Pr(J|S,B)$\", fontsize=14)\n",
      "plt.title(\"Likelihood of human and ideal observer judgments\", fontsize=16)\n",
      "\n",
      "fig.set_figwidth(8)\n",
      "fig.set_figheight(6)\n",
      "\n",
      "lat.save(\"images/model_performance.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving figure to images/model_performance.png...' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thetas = normalize(np.log(np.ones((1, n_trial+1, n_kappas))), axis=2)[1]\n",
      "window = 8\n",
      "lh = np.empty((n_trial-window, len(newconds), 3))\n",
      "x = np.arange(n_trial-window)\n",
      "for t in xrange(n_trial-window):\n",
      "    lh[t] = collapse(lat.fixed_model_lh(\n",
      "\tconds, experiment, ipe_samps, thetas, t, t+window, f_smooth))[0]\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(5)\n",
      "plt.clf()\n",
      "\n",
      "for cidx, cond in enumerate(newconds):\n",
      "    color = colors[cidx % len(colors)]\n",
      "    if cidx >= len(colors):\n",
      "\tlinestyle = '--'\n",
      "    else:\n",
      "\tlinestyle = '-'\n",
      "    plt.fill_between(x, lh[:, cidx, 1], lh[:, cidx, 2],\n",
      "\t\t     color=color, alpha=0.1)\n",
      "    plt.plot(lh[:, cidx, 0], color=color, label=cond, linestyle=linestyle)\n",
      "\n",
      "\t\n",
      "plt.legend(loc=0, ncol=3)\n",
      "fig.set_figwidth(8)\n",
      "fig.set_figheight(6)\n",
      "plt.xlim(0, n_trial-window-1)\n",
      "plt.xlabel(\"Trial\")\n",
      "plt.ylabel(\"Likelihood\")\n",
      "plt.title(\"Likelihood of observer responses, averaged over trial orderings\")\n",
      "plt.ylim(-7.5, -3.5)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(-7.5, -3.5)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p_response_mean = np.mean(p_responses, axis=2)\n",
      "p_response_sem = scipy.stats.sem(p_responses, axis=2)\n",
      "\n",
      "x = np.arange(n_trial)\n",
      "upper = p_response_mean + p_response_sem\n",
      "lower = p_response_mean - p_response_sem\n",
      "mean = p_response_mean\n",
      "\n",
      "#clr = ['r', 'b']\n",
      "k = 0 \n",
      "def plot(i, j, label):\n",
      "    global k\n",
      "    plt.fill_between(x, lower[i, j], upper[i, j], color=colors[k], alpha=0.1)\n",
      "    plt.plot(mean[i, j], color=colors[k], label=label)\n",
      "    k += 1\n",
      "\n",
      "plot(0, list(kappas).index(-1.0), \"learning, r=0.1\")\n",
      "plot(1, list(kappas).index(-1.0), \"fixed, r=0.1\")\n",
      "plot(2, 0, \"fixed, uniform\")\n",
      "plot(0, list(kappas).index(1.0), \"learning, r=10\")\n",
      "plot(1, list(kappas).index(1.0), \"fixed, r=10\")\n",
      "\t\n",
      "plt.legend(loc=0)\n",
      "fig = plt.gcf()\n",
      "fig.set_figwidth(8)\n",
      "fig.set_figheight(6)\n",
      "plt.xlim(0, n_trial-1)\n",
      "plt.xlabel(\"Trial\")\n",
      "plt.ylabel(\"Likelihood\")\n",
      "plt.title(\"Likelihood of observer responses, averaged over trial orderings\")\n",
      "plt.ylim(0.45, 0.6)\n",
      "\n",
      "lat.save(\"images/likelihoods_over_time.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'p_responses' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-307-f3bda8d89db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_response_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_responses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mp_response_sem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_responses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_response_mean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp_response_sem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'p_responses' is not defined"
       ]
      }
     ],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# model_thetas = np.empty((nsamp, n_kappas, n_trial+1, n_kappas))\n",
      "# for i in xrange(model_thetas.shape[0]):\n",
      "#     if i%10 == 0:\n",
      "# \tprint i\n",
      "#     model_lh, model_joint, model_theta = mo.ModelObserver(\n",
      "# \tipe_samps[orders[i]],\n",
      "# \tfeedback[orders[i]][:, None],\n",
      "# \toutcomes=None,\n",
      "# \trespond=False,\n",
      "# \tp_ignore_stimulus=p_ignore_stimulus,\n",
      "# \tsmooth=f_smooth)\n",
      "#     model_thetas[i] = model_theta\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# p_responses = np.empty((3, n_kappas, nsamp, n_trial))\n",
      "# theta_fixed = np.log(np.eye(n_kappas))\n",
      "\n",
      "# theta_uniform = normalize(np.log(np.ones(n_kappas)))[1]\n",
      "# sdata = np.asarray(ipe)\n",
      "\n",
      "# for i in xrange(nsamp):\n",
      "#     if i%10 == 0:\n",
      "# \tprint i\n",
      "#     sd = sdata[ikappa, orders[i]]\n",
      "#     for t in xrange(n_trial):\n",
      "# \t# learning\n",
      "# \tp_outcomes = np.exp(mo.predict(\n",
      "# \t    model_thetas[i, :, t],\n",
      "# \t    outcomes[:, None], \n",
      "# \t    ipe_samps[orders[i]][t],\n",
      "# \t    f_smooth))[:, 1]\n",
      "# \tresp = np.random.rand() < p_outcomes\n",
      "# \tp_responses[0, :, i, t] = (resp * sd[t]) + ((1-resp) * (1-sd[t]))\n",
      "\n",
      "# \t# fixed at true ratio\n",
      "# \tp_outcomes = np.exp(mo.predict(\n",
      "# \t    theta_fixed,\n",
      "# \t    outcomes[:, None], \n",
      "# \t    ipe_samps[orders[i]][t],\n",
      "# \t    f_smooth))[:, 1]\n",
      "# \tresp = np.random.rand() < p_outcomes\n",
      "# \tp_responses[1, :, i, t] = (resp * sd[t]) + ((1-resp) * (1-sd[t]))\n",
      "\n",
      "# \t# fixed at uniform belief\n",
      "# \tp_outcomes = np.exp(mo.predict(\n",
      "# \t    theta_uniform[None],\n",
      "# \t    outcomes[:, None], \n",
      "# \t    ipe_samps[orders[i]][t],\n",
      "# \t    f_smooth))[:, 1]\n",
      "# \tresp = np.random.rand() < p_outcomes\n",
      "# \tp_responses[2, :, i, t] = (resp * sd[t]) + ((1-resp) * (1-sd[t]))\n",
      "\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}