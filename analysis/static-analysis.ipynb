{
 "metadata": {
  "name": "static-analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports\n",
      "import collections\n",
      "import matplotlib.cm as cm\n",
      "import matplotlib.gridspec as gridspec\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pdb\n",
      "import pickle\n",
      "import scipy.stats\n",
      "import os\n",
      "import time\n",
      "\n",
      "import cogphysics\n",
      "import cogphysics.lib.circ as circ\n",
      "import cogphysics.lib.nplib as npl\n",
      "import cogphysics.lib.rvs as rvs\n",
      "\n",
      "import cogphysics.tower.analysis_tools as tat\n",
      "import cogphysics.tower.mass.model_observer as mo\n",
      "import cogphysics.tower.mass.learning_analysis_tools as lat\n",
      "\n",
      "from cogphysics.lib.corr import xcorr, partialcorr\n",
      "\n",
      "normalize = rvs.util.normalize\n",
      "weightedSample = rvs.util.weightedSample\n",
      "\n",
      "pd.set_option('line_width', 195)\n",
      "LINE = \"-\"*195\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Load stimuli\n",
      "######################################################################\n",
      "\n",
      "listpath = os.path.join(cogphysics.CPOBJ_LIST_PATH,\n",
      "\t\t\t\"mass-towers-stability-learning~kappa-1.0\")\n",
      "with open(listpath, \"r\") as fh:\n",
      "    Stims = np.array([x.split(\"~\")[0] for x in fh.read().strip().split(\"\\n\") if x != \"\"])\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Load human data\n",
      "######################################################################\n",
      "\n",
      "reload(lat)\n",
      "training, posttest, experiment, queries = lat.load_turk_static(thresh=1)\n",
      "conds = experiment.keys()\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-10-cb0.npz'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-0.1-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-0.1-cb0.npz'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loading '../../turk-experiment/data/consolidated_data/queries_data~B-fb-0.1-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/training_data~B-nfb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/posttest_data~B-nfb-10-cb1.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-nfb-10-cb0.npz'\n",
        "Loading '../../turk-experiment/data/consolidated_data/experiment_data~B-nfb-10-cb1.npz'\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Load model data\n",
      "######################################################################\n",
      "\n",
      "reload(lat)\n",
      "\n",
      "nthresh0 = 0\n",
      "nthresh = 0.4\n",
      "rawipe, ipe_samps, rawtruth, feedback, kappas = lat.process_model_turk(\n",
      "    Stims, nthresh0, nthresh)\n",
      "nofeedback = np.empty((feedback.shape[0], 1, 1))*np.nan\n",
      "\n",
      "fig = plt.figure(1)\n",
      "plt.clf()\n",
      "lat.plot_smoothing(rawipe, Stims, 6, nthresh, kappas)\n",
      "fig.set_figheight(6)\n",
      "fig.set_figwidth(8)\n",
      "\n",
      "lat.save(\"images/likelihood_smoothing.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving figure to images/likelihood_smoothing.png...' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Global parameters\n",
      "######################################################################\n",
      "\n",
      "n_kappas = len(kappas)\n",
      "ratios = 10 ** kappas\n",
      "ratios[kappas < 0] = np.round(ratios[kappas < 0], decimals=2)\n",
      "ratios[kappas >= 0] = np.round(ratios[kappas >= 0], decimals=1)\n",
      "ratios = list(ratios)\n",
      "kappas = list(kappas)\n",
      "\n",
      "outcomes     = np.array([0, 1])                  # possible outcomes\n",
      "n_trial      = Stims.size\n",
      "n_outcomes   = outcomes.size                     # number of possible outcomes\n",
      "\n",
      "f_smooth = True\n",
      "p_ignore_stimulus = 0.0\n",
      "\n",
      "cmap = lat.make_cmap(\"lh\", (0, 0, 0), (.5, .5, .5), (1, 0, 0))\n",
      "alpha = 0.2\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################\n",
      "## Generate fake human data\n",
      "######################################################################\n",
      "\n",
      "fig = plt.figure(2)\n",
      "plt.clf()\n",
      "plt.suptitle(\"Ideal Observer Beliefs\")\n",
      "cidx = 0\n",
      "\n",
      "reload(mo)\n",
      "nfake = 1000\n",
      "for cond in sorted(experiment.keys()):\n",
      "\n",
      "    group, fbtype, ratio, cb = lat.parse_condition(cond)\n",
      "    if group == \"MO\":\n",
      "\tcontinue\n",
      "\n",
      "    cols = experiment[cond].columns\n",
      "    order = np.argsort(zip(*cols)[0])\n",
      "    undo_order = np.argsort(order)\n",
      "\n",
      "    # determine what feedback to give\n",
      "    if fbtype == \"nfb\":\n",
      "\t#ridx = range(kappas.index(0.0)) + range(kappas.index(0.0)+1, n_kappas)\n",
      "\t#ridx = ratios.index(1.0)\n",
      "\tridx = np.arange(n_kappas)\n",
      "    else:\n",
      "\tridx = ratios.index(ratio)\n",
      "\t\n",
      "    fb = nofeedback[order][:, None]\n",
      "    initial = np.zeros((n_kappas))\n",
      "    initial[ridx] = 1\n",
      "    initial = normalize(np.log(initial))[1]\n",
      "    \n",
      "    # learning model beliefs\n",
      "    model_lh, model_joint, model_theta = mo.ModelObserver(\n",
      "\tipe_samps[order], fb,\n",
      "\toutcomes=None,\n",
      "\trespond=False,\n",
      "\tinitial=initial,\n",
      "\tp_ignore_stimulus=p_ignore_stimulus,\n",
      "\tsmooth=f_smooth)\n",
      "\n",
      "    # compute probability of falling\n",
      "    p_outcomes = np.empty((n_trial,))\n",
      "    for t in xrange(n_trial):\n",
      "\tnewcond = \"-\".join([\"MO\"] + cond.split(\"-\")[1:])\n",
      "\tp_outcomes[t] = np.exp(mo.predict(\n",
      "\t    model_theta[0, t][None],\n",
      "\t    outcomes[:, None], \n",
      "\t    ipe_samps[order][t],\n",
      "\t    f_smooth))[:, 1]\n",
      "\n",
      "    # sample responses\n",
      "    responses = np.random.rand(nfake)[:, None] < p_outcomes[None]\t\t\n",
      "    experiment[newcond] = pd.DataFrame(\n",
      "\tresponses[:, undo_order], \n",
      "\tcolumns=cols)\n",
      "\n",
      "    lat.plot_theta(\n",
      "\t1, 3, cidx+1,\n",
      "\tnp.exp(model_theta[0]),\n",
      "\tcond,\n",
      "\texp=1.3,\n",
      "\tcmap=cmap,\n",
      "\tfontsize=14)\n",
      "    cidx += 1\n",
      "\n",
      "conds = sorted(experiment.keys())\n",
      "lat.save(\"images/ideal_observer_beliefs.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving figure to images/ideal_observer_beliefs.png...' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(lat)\n",
      "\n",
      "nboot = 1000\n",
      "nsamp = 9\n",
      "with_replacement = False\n",
      "\n",
      "for cidx1, cond1 in enumerate(conds):\n",
      "    arr1 = np.asarray(experiment[cond1])\n",
      "    corrs = lat.bootcorr_wc(\n",
      "\tnp.asarray(arr1), \n",
      "\tnboot=nboot,\n",
      "\tnsamp=nsamp,\n",
      "\twith_replacement=with_replacement)\n",
      "    meancorr = np.mean(corrs)\n",
      "    semcorr = scipy.stats.sem(corrs)\n",
      "    print \"(bootstrap) %-15s v %-15s: rho = %.4f +/- %.4f\" % (\n",
      "\tcond1, cond1, meancorr, semcorr)\n",
      "\n",
      "    for cidx2, cond2 in enumerate(conds[cidx1+1:]):\n",
      "\tarr2 = np.asarray(experiment[cond2])\n",
      "\n",
      "\tcorrs = lat.bootcorr(\n",
      "\t    np.asarray(arr1), np.asarray(arr2), \n",
      "\t    nboot=nboot, \n",
      "\t    nsamp=nsamp,\n",
      "\t    with_replacement=with_replacement)\n",
      "\tmeancorr = np.mean(corrs)\n",
      "\tsemcorr = scipy.stats.sem(corrs)\n",
      "\tprint \"(bootstrap) %-15s v %-15s: rho = %.4f +/- %.4f\" % (\n",
      "\t    cond1, cond2, meancorr, semcorr)\n",
      "\n",
      "    print\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(bootstrap) B-fb-0.1        v B-fb-0.1       : rho = 0.3749 +/- 0.0040\n",
        "(bootstrap) B-fb-0.1        v B-fb-10        : rho = 0.3927 +/- 0.0047"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-0.1        v B-nfb-10       : rho = 0.4085 +/- 0.0042"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-0.1        v MO-fb-0.1      : rho = -0.1186 +/- 0.0050"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-0.1        v MO-fb-10       : rho = 0.2615 +/- 0.0044"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-0.1        v MO-nfb-10      : rho = 0.1031 +/- 0.0054"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "(bootstrap) B-fb-10         v B-fb-10        : rho = 0.5839 +/- 0.0036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-10         v B-nfb-10       : rho = 0.6786 +/- 0.0025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-10         v MO-fb-0.1      : rho = -0.1759 +/- 0.0048"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-10         v MO-fb-10       : rho = 0.0762 +/- 0.0040"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-fb-10         v MO-nfb-10      : rho = -0.0410 +/- 0.0043"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "(bootstrap) B-nfb-10        v B-nfb-10       : rho = 0.7135 +/- 0.0028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-nfb-10        v MO-fb-0.1      : rho = -0.2075 +/- 0.0042"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-nfb-10        v MO-fb-10       : rho = 0.0847 +/- 0.0032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) B-nfb-10        v MO-nfb-10      : rho = -0.0565 +/- 0.0032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "(bootstrap) MO-fb-0.1       v MO-fb-0.1      : rho = 0.9083 +/- 0.0019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-0.1       v MO-fb-10       : rho = 0.2583 +/- 0.0036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-0.1       v MO-nfb-10      : rho = 0.7127 +/- 0.0022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "(bootstrap) MO-fb-10        v MO-fb-10       : rho = 0.9029 +/- 0.0020"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(bootstrap) MO-fb-10        v MO-nfb-10      : rho = 0.7121 +/- 0.0024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "(bootstrap) MO-nfb-10       v MO-nfb-10      : rho = 0.8732 +/- 0.0029"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nfell = rawipe['nfellA'] + rawipe['nfellB']\n",
      "\n",
      "zscore = scipy.stats.zscore\n",
      "#zscore = lambda a, axis, ddof: a\n",
      "nanmean = scipy.stats.nanmean\n",
      "nanstd = scipy.stats.nanstd\n",
      "\n",
      "suffix = \"-fb-0.1\"\n",
      "\n",
      "hdata = zscore(np.asarray(experiment['B' + suffix]), axis=1, ddof=1)\n",
      "hmean = nanmean(hdata, axis=0)\n",
      "hsem = nanstd(hdata, axis=0) / np.sqrt(hdata.shape[0])\n",
      "\n",
      "sdata = zscore(ipe_samps[:, ratios.index(0.1), :, 0].T, axis=1, ddof=1)\n",
      "#sdata = zscore(nfell[:, ratios.index(0.1)].T, axis=1, ddof=1)\n",
      "#sdata = zscore(np.asarray(experiment['MO' + suffix]), axis=1, ddof=1)\n",
      "smean = nanmean(sdata, axis=0)\n",
      "ssem = nanstd(sdata, axis=0) / np.sqrt(sdata.shape[0])\n",
      "\n",
      "print xcorr(hmean, smean)\n",
      "\n",
      "plt.figure(3)\n",
      "plt.clf()\n",
      "plt.errorbar(hmean, smean, xerr=hsem, yerr=ssem, \n",
      "\t     linestyle='', marker='o')\n",
      "plt.xlabel(\"Human n=%d (no feedback)\" % hdata.shape[0])\n",
      "plt.ylabel(\"Model n=%d (uniform prior, no learning)\" % sdata.shape[0])\n",
      "plt.title(\"Human vs. model judgments\")\n",
      "\n",
      "lat.save(\"images/human_v_model.png\", close=False)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-0.140601991115\n",
        "Saving figure to images/human_v_model.png...'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Done\n"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(10)\n",
      "plt.clf()\n",
      "\n",
      "for cond in conds:\n",
      "    if cond.startswith(\"MO\"):\n",
      "\tcontinue\n",
      "    if cond.endswith(\"nfb-10\"):\n",
      "\tcontinue\n",
      "\n",
      "    ratio = float(cond.split(\"-\")[-1])\n",
      "    arr = np.asarray(queries[cond]) == ratio\n",
      "    mean = np.mean(arr, axis=0)\n",
      "    sem = scipy.stats.sem(arr, axis=0, ddof=1)\n",
      "    print mean\n",
      "    plt.errorbar(np.arange(mean.shape[0]), mean, yerr=sem, \n",
      "\t\t label=\"r=%s (n=%d)\"% (cond.split(\"-\")[-1], arr.shape[0]))\n",
      "\n",
      "plt.xlim(-.5, 3.5)\n",
      "plt.xticks([0, 1, 2, 3], [5, 10, 15, 20])\n",
      "plt.xlabel(\"Trial\")\n",
      "plt.ylabel(\"P(judge correct mass ratio)\")\n",
      "plt.title(\"Explicit mass judgments\")\n",
      "plt.legend(loc=0)\n",
      "\n",
      "lat.save(\"images/explicit_mass_judgments.png\", close=False)\n",
      "    "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.33333333  0.77777778  0.5         0.88888889]\n",
        "[ 0.73684211  0.68421053  0.84210526  0.89473684]\n",
        "Saving figure to images/explicit_mass_judgments.png...'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Done\n"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}