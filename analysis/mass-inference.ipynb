{
 "metadata": {
  "name": "",
  "signature": "sha256:38f373d00250c448beeb8078f52b5863cbf3327656a8694710663bd1d58e00f8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%matplotlib inline\n",
      "\n",
      "import analyses\n",
      "import plots\n",
      "import analyses.util as util\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from IPython.display import Image\n",
      "from path import path\n",
      "from ConfigParser import SafeConfigParser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = util.load_all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Inferring mass in complex physical scenes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Jessica B. Hamrick, Peter W. Battaglia, Thomas L. Griffiths, Joshua B. Tenenbaum"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "IPE"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We ran 100 IPE samples for each stimulus for 27 different values of $\\kappa=\\log_{10}(r)$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kappas = np.asarray(data['ipe']['B'].data['kappa'].drop_duplicates())\n",
      "print \"Unique kappa values:\", kappas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From these IPE samples, we can compute estimates of $p(\\mathrm{fall}\\ \\vert\\ \\kappa, S)$ for each stimulus $S$. In order to enforce that this curve is continuous in the domain of $\\kappa$, we apply a kernel smoothing procedure. For example, the following plot shows the raw estimates of $p(\\mathrm{fall}\\ \\vert\\ \\kappa, S)$ for one particular $S$ (blue dots), as well as the final smoothed estimate (black line)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "data['ipe']['C'].plot(i)\n",
      "data['empirical']['C'].plot(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We ran two experiments in which participants made judgments about the stability and mass of towers of building blocks. Both experiments were organized as follows:\n",
      "\n",
      "* Pretest: \"will it fall?\" judgments on 6 original (non-mass) towers\n",
      "* Block A: \"will it fall?\" judgments on 10 red/blue mass towers, with visual feedback\n",
      "* Block B: \"will it fall?\" judgments on 20 red/blue mass towers, with no feedback\n",
      "* Block C: \"which is heavier?\" judgments on the same towers as in Block B, with visual feedback\n",
      "* Posttest: same as pretest, but different order\n",
      "\n",
      "The difference between Experiment 1 and Experiment 2 was in block C. In Experiment 1, the colors of the blocks were different on every trial. In Experiment 2, the colors were always green and purple. Thus, in Experiment 1, participants had to make inferences based off of information from just a single trial, whereas in Experiment 2, participants had to integrate information about the mass over multiple trials.\n",
      "\n",
      "The mass ratio was always the same for blocks A and B, but could be different for Block C, giving four conditions:\n",
      "\n",
      "* Condition 0: A, B: $r=0.1$, C: $r=0.1$\n",
      "* Condition 1: A, B: $r=0.1$, C: $r=10$\n",
      "* Condition 2: A, B: $r=10$, C: $r=0.1$\n",
      "* Condition 3: A, B: $r=10$, C: $r=10$\n",
      "\n",
      "Additionally, we counterbalanced the colors, resulting in a total of eight conditions. People were distributed into the conditions as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make condition_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cond_counts = pd.read_csv(\"results/condition_counts.csv\")\\\n",
      "    .set_index(['version', 'condition', 'counterbalance'])\\\n",
      "    .unstack('version')\n",
      "cond_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make num_participants"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/num_participants.csv\", index_col=\"version\").T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Participants were paid either \\$1.25 (Experiment 1), \\$1.00 (Experiment 2), or \\$0.70 (Experiment 3):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make payrate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/payrate.csv\").set_index('version')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Can people reason with mass?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Previous research \\cite{Battaglia2013} indicated that people can take information about the mass of objects into account when reasoning about physical properties like stability. The first parts of our experiment (Block A and Block B) were essentially the same design as that from \\citeA{Battalia2013}, so we should see the same trends as in Battaliga2013.\n",
      "\n",
      "First, we can take a look at how well the IPE estimates of $p(\\mathrm{fall}\\ \\vert\\ \\kappa_0, S)$ predict human judgments of stability. In the following plots, the $x$-axis is the IPE's estimate of $p(\\mathrm{fall}\\ \\vert\\ \\kappa, S)$ for $\\kappa=\\kappa_0$ (center subplots) and $\\kappa=0.0$ (right subplots). The $y$-axis is people's judgments of stability on a scale from 1-7, with 1 being less stable, and 7 being more stable. The black lines connect stimuli with the same geometry.\n",
      "\n",
      "These plots illustrate the same trend that was previously found: people are sensitive to the information about mass. In the left plots, we see that people give different judgments for stimuli with identical when they are told that the mass ratio is different. The IPE does the same when it is given information about mass (center plots). As such, IPE predictions that were generated without knowledge of mass are poor predictions of human judgments (right plots)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make fall_responses\n",
      "make fall_response_corrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "\"Will it fall?\" responses from block A"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot \"will it fall?\" responses for block A\n",
      "Image(\"figures/fall_responses_GH_A.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are the corresponding Pearson correlations for the above plots (`ModelIS` is the mass-insensitive IPE, and `ModelS` is the mass-sensitive IPE)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/fall_response_corrs.csv\").set_index(['block', 'X', 'Y']).ix['A']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "\"Will it fall?\" responses from block B"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot \"will it fall?\" responses for block B\n",
      "Image(\"figures/fall_responses_GH_B.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are the corresponding Pearson correlations for the above plots (`ModelIS` is the mass-insensitive IPE, and `ModelS` is the mass-sensitive IPE)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/fall_response_corrs.csv\").set_index(['block', 'X', 'Y']).ix['B']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Can people infer mass?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we can make an argument that people infer mass in a manner consistent with the \"noisy Newton\" approach, we must first demonstrate that people can make inferences about mass at all. Recent research (Sanborn2013) has explained how previous results suggesting people do not make sophisticated inferences about mass (Todd1982, Gilden1994) can be explained using Bayesian inference. However, no one has yet shown whether this also holds true in more complicated, realistic scenes.\n",
      "\n",
      "We can examine the accuracy of \"which is heavier?\" judgments from block C of the experiment to see whether people are judging the heavier color actually as heavier. If they are guessing randomly, then we should see around 50% accuracy. If they are correctly inferring the mass, then their accuracy should be above 50%."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Overall accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As shown by the following table, people are (across stimuli) above chance at determining the heavier color, regardless of the mass ratio:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make mass_accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/mass_accuracy.csv\")\\\n",
      "    .groupby(['species', 'version'])\\\n",
      "    .get_group(('human', 'H'))\\\n",
      "    .set_index('kappa0')\\\n",
      "    .drop(['species', 'class', 'version'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Per-stimulus accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that people are also above chance on many of the individual stimuli, though there are a few stimuli for which people are at chance:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make mass_accuracy_by_stimulus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(\"figures/mass_accuracy_by_stimulus.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specifically, significantly above chance on 31 of these stimuli, and not significantly above chance for 9 of these stimuli (using Bonferroni correction for multiple comparisons):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make num_chance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/num_chance.csv\").set_index(['kappa0', 'stimulus']).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "How do people infer mass?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Human vs. model accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Are the stimuli that people are better at inferring mass from the same stimuli that the model is good at inferring mass from? We see that the original IPE is not very correlated with people, but the IPE based off of people's \"fall?\" judgments is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make mass_responses_by_stimulus\n",
      "make mass_responses_by_stimulus_corrs\n",
      "make mass_accuracy_by_stimulus_corrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(\"figures/mass_responses_by_stimulus.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/mass_responses_by_stimulus_corrs.csv\").groupby('version').get_group('H').set_index(['X', 'Y'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/mass_accuracy_by_stimulus_corrs.csv\").groupby('version').get_group('H').set_index(['X', 'Y'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Do people integrate information over time?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following plot does not show a clear effect of learning over time -- just that people are above chance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make mass_accuracy_by_trial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(\"figures/mass_accuracy_by_trial.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make mass_accuracy_by_trial_corrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"results/mass_accuracy_by_trial_corrs.csv\")\\\n",
      "    .groupby('kappa0')\\\n",
      "    .get_group('all')\\\n",
      "    .drop('kappa0', axis=1)\\\n",
      "    .set_index(['version', 'num_mass_trials'])\\\n",
      "    .sortlevel()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we look more closely at individual participants, we see that the majority of them did eventually figure out which color was heavier. The following plots shows the fraction of participants who gave the correct answer on trial $t$ and all trials afterwards. In both conditions, the majority of participatns eventually figured out the which color was heavier, however there were also some participants who never settled on the correct answer. It is possible that these participants were confused about the instructions, and did not realize that the heavier color was always the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make num_learned_by_trial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(\"figures/num_learned_by_trial.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To look at the data from a slightly different angle, we can compare three different inference models:\n",
      "\n",
      "* `chance` -- guesses uniformly at random, reflecting the hypothesis that people do not make any inferences about mass\n",
      "* `learning` -- updates its beliefs according to Bayes' rule, using physical knowledge from the IPE\n",
      "* `static` -- uses physical knowledge from the IPE, but only considers information from the most recent trial (does not update beliefs)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both models which utilize knowledge from the IPE are better explanations of people's behavior than a model that guesses randomly:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make model_log_lh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "llh = pd.read_csv(\"results/model_log_lh.csv\")\\\n",
      "    .groupby(['version', 'likelihood', 'model', 'pid'])['llh']\\\n",
      "    .sum()\\\n",
      "    .unstack('likelihood')\n",
      "llh.groupby(level=['version', 'model']).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Moreover, if we look at the individual breakdown of which participants were best explained by which model, we find that the vast majority of participants had the best match with one of the IPE models:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "make participant_fits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ranks = pd.read_csv(\"results/participant_fits.csv\")\n",
      "ranks.groupby('version').apply(lambda x: x.groupby('rank').get_group(0).groupby('model').agg(len))['pid'].unstack('version')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}