How do people infer unobserved physical properties of objects from
very complex scenes, such as the masses of many objects involved in a
cascade of collisions? We propose that these judgments can be
explained as Bayesian inferences informed by approximate Newtonian
mechanics. We built a quantitative model observer that uses
probabilistic simulations to predict the effects of physics on complex
scenes, and which updates its beliefs about the underlying physical
parameters by comparing these predictions to the observed physical
dynamics. Our results show that people can learn the relative masses
among objects in a scene by observing their interactions across
multiple trial presentations, and that their judgments well-match the
patterns of responses exhibited by the model as it learns. People were
generally accurate at both explicitly reporting what they have
learned, as well as implicitly demonstrating their learning through
their predictions about object dynamics. We also found that they can
learn both from rich visual feedback about the dynamics as well as
minimal, binary feedback. We conclude that people's judgments are
consistent with Bayesian inferences under an approximate Newtonian
generative model and that probabilistic simulation is a strong
candidate for the mechanism of these inferences.
