How do people infer the relative masses of objects in highly complex
scenes, such as a tower of building blocks? We propose that people's
judgments can be explained by Bayesian inferences over a model of
approximate Newtonian mechanics. We built a quantitative model
observer which uses stochastic physical simulations to predict future
dynamics, and which updates its beliefs about the underlying
parameters by comparing its predictions to observed feedback. Our
results show that people can learn the relative masses of objects by
observing their interactions across multiple trial presentations, and
that their judgments are consistent with the patterns of responses
exhibited by the model as it learns. Moreover, participants were able
to learn both from rich visual feedback as well as minimal, binary
feedback. We suggest that to infer unobservable properties like mass,
people integrate an ideal learning stragety with approximate knowledge
of physical dynamics in a near-optimal manner.
